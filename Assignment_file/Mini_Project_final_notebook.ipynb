{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334cb216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from kagglehub import KaggleDatasetAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87292a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   reviewer_id  store_name              category  \\\n",
      "0            1  McDonald's  Fast food restaurant   \n",
      "1            2  McDonald's  Fast food restaurant   \n",
      "2            3  McDonald's  Fast food restaurant   \n",
      "3            4  McDonald's  Fast food restaurant   \n",
      "4            5  McDonald's  Fast food restaurant   \n",
      "\n",
      "                                       store_address  latitude   longitude  \\\n",
      "0  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
      "1  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
      "2  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
      "3  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
      "4  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
      "\n",
      "  rating_count   review_time  \\\n",
      "0        1,240  3 months ago   \n",
      "1        1,240    5 days ago   \n",
      "2        1,240    5 days ago   \n",
      "3        1,240   a month ago   \n",
      "4        1,240  2 months ago   \n",
      "\n",
      "                                              review   rating  \n",
      "0  Why does it look like someone spit on my food?...   1 star  \n",
      "1  It'd McDonalds. It is what it is as far as the...  4 stars  \n",
      "2  Made a mobile order got to the speaker and che...   1 star  \n",
      "3  My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...  5 stars  \n",
      "4  I repeat my order 3 times in the drive thru, a...   1 star  \n",
      "\n",
      "Shape:  (33396, 10)\n",
      "Missing values before handling:\n",
      "reviewer_id        0\n",
      "store_name         0\n",
      "category           0\n",
      "store_address      0\n",
      "latitude         660\n",
      "longitude        660\n",
      "rating_count       0\n",
      "review_time        0\n",
      "review             0\n",
      "rating             0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after handling:\n",
      "reviewer_id      0\n",
      "store_name       0\n",
      "category         0\n",
      "store_address    0\n",
      "latitude         0\n",
      "longitude        0\n",
      "rating_count     0\n",
      "review_time      0\n",
      "review           0\n",
      "rating           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\AppData\\Local\\Temp\\ipykernel_23144\\4095640643.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['latitude'].fillna(df['latitude'].mean(), inplace=True)\n",
      "C:\\Users\\prath\\AppData\\Local\\Temp\\ipykernel_23144\\4095640643.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['longitude'].fillna(df['longitude'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset\n",
    "#df = pd.read_csv(\"drive/MyDrive/McDonald_s_Reviews.csv\", encoding=\"latin1\")\n",
    "df = pd.read_csv(\"McDonald_s_Reviews.csv\", encoding=\"latin1\")\n",
    "print(df.head())\n",
    "print(\"\\nShape: \", df.shape)\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"Missing values before handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values numerical columns with median\n",
    "df['latitude'].fillna(df['latitude'].mean(), inplace=True)\n",
    "df['longitude'].fillna(df['longitude'].mean(), inplace=True)\n",
    "\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1848b1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>3 months ago</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>It'd McDonalds. It is what it is as far as the...</td>\n",
       "      <td>4 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Made a mobile order got to the speaker and che...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>I repeat my order 3 times in the drive thru, a...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       store_address   latitude  longitude  \\\n",
       "0  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "1  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "2  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "3  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "4  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "\n",
       "  rating_count   review_time  \\\n",
       "0        1,240  3 months ago   \n",
       "1        1,240    5 days ago   \n",
       "2        1,240    5 days ago   \n",
       "3        1,240   a month ago   \n",
       "4        1,240  2 months ago   \n",
       "\n",
       "                                              review   rating  \n",
       "0  Why does it look like someone spit on my food?...   1 star  \n",
       "1  It'd McDonalds. It is what it is as far as the...  4 stars  \n",
       "2  Made a mobile order got to the speaker and che...   1 star  \n",
       "3  My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...  5 stars  \n",
       "4  I repeat my order 3 times in the drive thru, a...   1 star  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing unnecessary features\n",
    "df = df.drop(\"reviewer_id\", axis=1)\n",
    "df = df.drop(\"store_name\", axis=1)\n",
    "df = df.drop(\"category\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb39992f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1240</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1240</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It'd McDonalds. It is what it is as far as the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1240</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Made a mobile order got to the speaker and che...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1240</td>\n",
       "      <td>60.0</td>\n",
       "      <td>I repeat my order 3 times in the drive thru, a...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_address   latitude  longitude  rating_count  review_time  \\\n",
       "0              8  30.460718 -97.792874          1240         90.0   \n",
       "1              8  30.460718 -97.792874          1240          5.0   \n",
       "2              8  30.460718 -97.792874          1240          5.0   \n",
       "3              8  30.460718 -97.792874          1240          NaN   \n",
       "4              8  30.460718 -97.792874          1240         60.0   \n",
       "\n",
       "                                              review  rating  \n",
       "0  Why does it look like someone spit on my food?...      -1  \n",
       "1  It'd McDonalds. It is what it is as far as the...       1  \n",
       "2  Made a mobile order got to the speaker and che...      -1  \n",
       "3  My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...       1  \n",
       "4  I repeat my order 3 times in the drive thru, a...      -1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode rating column\n",
    "df['rating'] = df['rating'].astype(str).str.extract(r'(\\d)').astype(int)\n",
    "df['rating'] = df['rating'].map(lambda x: -1 if x <= 2 else (0 if x == 3 else 1))\n",
    "\n",
    "#Encode rating_count\n",
    "df['rating_count'] = df['rating_count'].str.replace(',', '').astype(int)\n",
    "\n",
    "#Encode store_address\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Encode store_address\n",
    "le = LabelEncoder()\n",
    "df['store_address'] = le.fit_transform(df['store_address'])\n",
    "\n",
    "#Encode review_time\n",
    "import re\n",
    "\n",
    "def convert_review_time(time_str):\n",
    "    if pd.isna(time_str):  # Handle missing values\n",
    "        return None\n",
    "\n",
    "    match = re.search(r'\\d+', str(time_str))  # Ensure it's a string\n",
    "    if not match:\n",
    "        return None  # If no number is found, return None\n",
    "\n",
    "    num = int(match.group())  # Extract number\n",
    "\n",
    "    if \"day\" in time_str:\n",
    "        return num\n",
    "    elif \"month\" in time_str:\n",
    "        return num * 30\n",
    "    elif \"year\" in time_str:\n",
    "        return num * 365\n",
    "    else:\n",
    "        return None  # Catch unexpected cases\n",
    "\n",
    "df['review_time'] = df['review_time'].apply(convert_review_time)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd8efa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>review_time</th>\n",
       "      <th>rating</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>area</th>\n",
       "      <th>ask</th>\n",
       "      <th>...</th>\n",
       "      <th>waiting</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>went</th>\n",
       "      <th>window</th>\n",
       "      <th>work</th>\n",
       "      <th>worst</th>\n",
       "      <th>wrong</th>\n",
       "      <th>½s</th>\n",
       "      <th>½ï</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1240</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1240</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1240</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1240</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_address   latitude  longitude  rating_count  review_time  rating  \\\n",
       "0              8  30.460718 -97.792874          1240         90.0      -1   \n",
       "1              8  30.460718 -97.792874          1240          5.0       1   \n",
       "2              8  30.460718 -97.792874          1240          5.0      -1   \n",
       "3              8  30.460718 -97.792874          1240          NaN       1   \n",
       "4              8  30.460718 -97.792874          1240         60.0      -1   \n",
       "\n",
       "    10   20  area  ask  ...  waiting      want  way      went  window  \\\n",
       "0  0.0  0.0   0.0  0.0  ...      0.0  0.527387  0.0  0.000000     0.0   \n",
       "1  0.0  0.0   0.0  0.0  ...      0.0  0.000000  0.0  0.000000     0.0   \n",
       "2  0.0  0.0   0.0  0.0  ...      0.0  0.000000  0.0  0.048056     0.0   \n",
       "3  0.0  0.0   0.0  0.0  ...      0.0  0.000000  0.0  0.000000     0.0   \n",
       "4  0.0  0.0   0.0  0.0  ...      0.0  0.000000  0.0  0.000000     0.0   \n",
       "\n",
       "       work  worst     wrong   ½s        ½ï  \n",
       "0  0.000000    0.0  0.000000  0.0  0.000000  \n",
       "1  0.000000    0.0  0.000000  0.0  0.000000  \n",
       "2  0.053121    0.0  0.000000  0.0  0.986156  \n",
       "3  0.000000    0.0  0.000000  0.0  0.997586  \n",
       "4  0.283198    0.0  0.263631  0.0  0.000000  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=100)  # Limit to 100 features\n",
    "\n",
    "# Transform the text column\n",
    "tfidf_matrix = vectorizer.fit_transform(df['review'].fillna(\"\"))  # Convert NaN to empty strings\n",
    "\n",
    "# Convert sparse matrix to DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Merge with original dataset (drop original review column)\n",
    "df = pd.concat([df.drop(columns=['review']), tfidf_df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "743b7a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['10', '20', 'area', 'ask', 'asked', 'bad', 'best', 'better', 'big',\n",
       "       'breakfast', 'burger', 'busy', 'came', 'chicken', 'clean', 'coffee',\n",
       "       'cold', 'come', 'customer', 'customers', 'day', 'did', 'didn', 'dirty',\n",
       "       'don', 'drive', 'eat', 'employees', 'excellent', 'experience', 'fast',\n",
       "       'food', 'fresh', 'friendly', 'fries', 'gave', 'going', 'good', 'got',\n",
       "       'great', 'homeless', 'horrible', 'hot', 'ice', 'inside', 'just', 'kids',\n",
       "       'know', 'like', 'line', 'location', 'long', 'lot', 'love', 'make',\n",
       "       'manager', 'mcdonald', 'mcdonalds', 'meal', 'minutes', 'need',\n",
       "       'neutral', 'new', 'nice', 'night', 'open', 'order', 'ordered', 'orders',\n",
       "       'people', 'place', 'poor', 'quick', 'really', 'restaurant', 'right',\n",
       "       'rude', 'said', 'say', 'service', 'slow', 'staff', 'terrible', 'time',\n",
       "       'times', 'told', 'took', 've', 'wait', 'waited', 'waiting', 'want',\n",
       "       'way', 'went', 'window', 'work', 'worst', 'wrong', '½s', '½ï'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes review column and adds these columns\n",
    "tfidf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c7014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['store_address', 'latitude', 'longitude', 'rating_count', 'review_time',\n",
      "       '10', '20', 'area', 'ask', 'asked', 'bad', 'best', 'better',\n",
      "       'breakfast', 'burger', 'busy', 'came', 'chicken', 'clean', 'cold',\n",
      "       'come', 'customer', 'customers', 'day', 'did', 'didn', 'dirty', 'don',\n",
      "       'drive', 'eat', 'employees', 'excellent', 'experience', 'fast', 'food',\n",
      "       'fresh', 'friendly', 'fries', 'gave', 'going', 'good', 'got', 'great',\n",
      "       'homeless', 'horrible', 'hot', 'ice', 'inside', 'just', 'kids', 'know',\n",
      "       'like', 'line', 'location', 'long', 'lot', 'love', 'make', 'manager',\n",
      "       'mcdonald', 'meal', 'minutes', 'need', 'neutral', 'nice', 'night',\n",
      "       'open', 'order', 'ordered', 'orders', 'people', 'place', 'poor',\n",
      "       'quick', 'right', 'rude', 'said', 'say', 'service', 'slow', 'staff',\n",
      "       'terrible', 'time', 'times', 'told', 'took', 've', 'wait', 'waited',\n",
      "       'waiting', 'want', 'way', 'went', 'window', 'work', 'worst', 'wrong',\n",
      "       '½s', '½ï'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop columns that are completely empty\n",
    "X = df.drop(columns=['rating'])\n",
    "X = X.dropna(axis=1, how='all')  # Drop columns where all values are NaN\n",
    "\n",
    "# Apply imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# SelectKBest for feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=99)\n",
    "X_selected = selector.fit_transform(df_imputed, df['rating'])\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "# Convert selected features into DataFrame\n",
    "df_selected = pd.DataFrame(X_selected, columns=selected_features)\n",
    "\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1287df8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "-1    16061\n",
      " 1    16061\n",
      " 0    16061\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define feature matrix (X) and target variable (y)\n",
    "X = df_selected  # Features from previous feature selection step\n",
    "y = df['rating']  # Target variable\n",
    "\n",
    "# Apply RandomOverSampler to balance dataset\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = oversampler.fit_resample(X, y)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df_balanced = pd.DataFrame(X_balanced, columns=X.columns)\n",
    "df_balanced['rating'] = y_balanced  # Add the target column back\n",
    "\n",
    "print(df_balanced['rating'].value_counts())  # Check class distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "418d4318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (33728, 99), (33728,)\n",
      "Validation set: (7227, 99), (7227,)\n",
      "Test set: (7228, 99), (7228,)\n"
     ]
    }
   ],
   "source": [
    "# Split the Data\n",
    "X = df_selected\n",
    "y = df['rating']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Re-apply imputation AFTER splitting\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_val = imputer.transform(X_val)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe19dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "\n",
      "🔹 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.86      0.85      2388\n",
      "           0       0.84      0.92      0.88      2464\n",
      "           1       0.87      0.76      0.81      2376\n",
      "\n",
      "    accuracy                           0.85      7228\n",
      "   macro avg       0.85      0.85      0.84      7228\n",
      "weighted avg       0.85      0.85      0.84      7228\n",
      "\n",
      "Accuracy: 0.8462\n",
      "Precision: 0.8472\n",
      "Recall: 0.8462\n",
      "F1-score: 0.8450\n",
      "MCC: 0.7706\n",
      "Cohen's Kappa: 0.7691\n",
      "ROC-AUC Score: 0.9524\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2051  181  156]\n",
      " [  84 2255  125]\n",
      " [ 312  254 1810]]\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(f\"Random Forest\")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,\n",
    "    roc_auc_score, matthews_corrcoef, cohen_kappa_score, classification_report\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute Performance Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "# Multi-class ROC-AUC Score (Fixed)\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))  # Convert to one-hot encoding\n",
    "roc_auc = roc_auc_score(y_test_bin, rf_model.predict_proba(X_test), multi_class=\"ovr\")\n",
    "\n",
    "# 4️⃣ Print Metrics\n",
    "print(\"\\n🔹 Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa:.4f}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b7f5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 0.6346\n",
      "Precision: 0.6402\n",
      "MCC: 0.4571\n",
      "Kappa score: 0.4522\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.78      0.68      2388\n",
      "           0       0.58      0.50      0.54      2464\n",
      "           1       0.74      0.63      0.68      2376\n",
      "\n",
      "    accuracy                           0.63      7228\n",
      "   macro avg       0.64      0.64      0.63      7228\n",
      "weighted avg       0.64      0.63      0.63      7228\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1866  426   96]\n",
      " [ 792 1234  438]\n",
      " [ 436  453 1487]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predictions\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "print(f\"Logistic Regression\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(f\"MCC: {mcc:.4f}\")\n",
    "\n",
    "cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(f\"Kappa score: {cohen_kappa:.4f}\")\n",
    "\n",
    "# Classification Report (Precision, Recall, F1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b55cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'max_depth': 20,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest (Model 42 – Best)\n",
    "{\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 20,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'bootstrap': False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d44b8b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 500, 'C': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression (Top 1)\n",
    "{\n",
    "    'solver': 'lbfgs',\n",
    "    'penalty': 'l2',\n",
    "    'max_iter': 500,\n",
    "    'C': 10\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fc66783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features: 99\n",
      "Reduced Features (PCA): 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to reduce dimensions while keeping 95% variance\n",
    "pca = PCA(n_components=30)  # Adjust components as needed\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(f\"Original Features: {X_train.shape[1]}\")\n",
    "print(f\"Reduced Features (PCA): {X_train_pca.shape[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0146cd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📢 Ensemble Model Evaluation:\n",
      "✅ Accuracy: 0.7393\n",
      "✅ MCC: 0.6262\n",
      "✅ Kappa Score: 0.6087\n",
      "\n",
      "✅ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.91      0.74      2424\n",
      "           0       0.80      0.64      0.71      2374\n",
      "           1       0.90      0.66      0.76      2429\n",
      "\n",
      "    accuracy                           0.74      7227\n",
      "   macro avg       0.78      0.74      0.74      7227\n",
      "weighted avg       0.78      0.74      0.74      7227\n",
      "\n",
      "\n",
      "🧮 Confusion Matrix:\n",
      "[[2213  118   93]\n",
      " [ 768 1520   86]\n",
      " [ 568  251 1610]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rf_lr_ensemble_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, matthews_corrcoef, cohen_kappa_score, \n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import joblib\n",
    "\n",
    "# 🧪 Optional: If not already done, apply PCA and load the reduced data\n",
    "# X_train_pca, X_val_pca, y_train, y_val should already be defined\n",
    "\n",
    "# ✅ 1. Best Random Forest Model\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    bootstrap=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ✅ 2. Best Logistic Regression Model\n",
    "best_lr = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    penalty='l2',\n",
    "    max_iter=500,\n",
    "    C=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ✅ 3. Voting Ensemble using hard voting\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('RandomForest', best_rf),\n",
    "        ('LogisticRegression', best_lr)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# 🚀 Fit the ensemble\n",
    "ensemble_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# 📊 Predict and evaluate\n",
    "y_pred = ensemble_model.predict(X_val_pca)\n",
    "\n",
    "print(\"\\n📢 Ensemble Model Evaluation:\")\n",
    "print(f\"✅ Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(f\"✅ MCC: {matthews_corrcoef(y_val, y_pred):.4f}\")\n",
    "print(f\"✅ Kappa Score: {cohen_kappa_score(y_val, y_pred):.4f}\")\n",
    "print(\"\\n✅ Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"\\n🧮 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "# 💾 Save the ensemble model\n",
    "joblib.dump(ensemble_model, \"rf_lr_ensemble_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d30cca9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Evaluation: Voting Classifier (RF + LR + DT)\n",
      "Accuracy: 0.8307\n",
      "MCC: 0.7480\n",
      "Kappa Score: 0.7457\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.82      0.83      2388\n",
      "           0       0.80      0.92      0.86      2464\n",
      "           1       0.85      0.75      0.80      2376\n",
      "\n",
      "    accuracy                           0.83      7228\n",
      "   macro avg       0.83      0.83      0.83      7228\n",
      "weighted avg       0.83      0.83      0.83      7228\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1958  236  194]\n",
      " [  82 2266  116]\n",
      " [ 279  317 1780]]\n",
      "✅ Saved model to: Voting_Classifier_RF_plus_LR_plus_DT.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, cohen_kappa_score, classification_report, confusion_matrix\n",
    "\n",
    "# Random Forest: Best Parameters from Your Search (Model 41)\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    bootstrap=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Logistic Regression: Best Parameters from Your Search\n",
    "best_lr = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    penalty='l2',\n",
    "    max_iter=500,\n",
    "    C=10,\n",
    "    multi_class='auto',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Decision Tree with default or basic tuning (can be tuned later if needed)\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# ✅ 1. Voting Classifier (Soft Voting)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', best_rf),\n",
    "        ('lr', best_lr),\n",
    "        ('dt', dt_clf)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "# ✅ 2. Bagging Classifier (with Decision Tree)\n",
    "bagging_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=50,\n",
    "    max_samples=0.8,\n",
    "    max_features=0.8,\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Training and Evaluation Function ---\n",
    "def evaluate_model(model, name, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\n✅ Evaluation: {name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"MCC: {matthews_corrcoef(y_test, y_pred):.4f}\")\n",
    "    print(f\"Kappa Score: {cohen_kappa_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# --- Run All Models ---\n",
    "models = [\n",
    "    (voting_clf, \"Voting Classifier (RF + LR + DT)\"),\n",
    "\n",
    "]\n",
    "\n",
    "import joblib\n",
    "\n",
    "for model, name in models:\n",
    "    evaluate_model(model, name, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Save model\n",
    "    filename = name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"+\", \"plus\") + \".pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"✅ Saved model to: {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b6b517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bd4c569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluation: Voting Classifier (RF + LR + KNN)\n",
      "Accuracy: 0.8087\n",
      "MCC: 0.7152\n",
      "Kappa Score: 0.7127\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.79      0.81      2388\n",
      "           0       0.77      0.90      0.83      2464\n",
      "           1       0.83      0.73      0.78      2376\n",
      "\n",
      "    accuracy                           0.81      7228\n",
      "   macro avg       0.81      0.81      0.81      7228\n",
      "weighted avg       0.81      0.81      0.81      7228\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1897  291  200]\n",
      " [  95 2209  160]\n",
      " [ 277  360 1739]]\n",
      "✅ Model saved as: Voting_Classifier_RF_plus_LR_plus_KNN.pkl\n",
      "\n",
      "🔍 Evaluation: Bagging Classifier (DT)\n",
      "Accuracy: 0.8554\n",
      "MCC: 0.7841\n",
      "Kappa Score: 0.7830\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.86      0.86      2388\n",
      "           0       0.84      0.92      0.88      2464\n",
      "           1       0.86      0.79      0.82      2376\n",
      "\n",
      "    accuracy                           0.86      7228\n",
      "   macro avg       0.86      0.85      0.85      7228\n",
      "weighted avg       0.86      0.86      0.85      7228\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2043  173  172]\n",
      " [  73 2267  124]\n",
      " [ 247  256 1873]]\n",
      "✅ Model saved as: Bagging_Classifier_DT.pkl\n",
      "\n",
      "🔍 Evaluation: AdaBoost Classifier\n",
      "Accuracy: 0.5766\n",
      "MCC: 0.4272\n",
      "Kappa Score: 0.3675\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.48      0.94      0.64      2388\n",
      "           0       0.99      0.20      0.34      2464\n",
      "           1       0.69      0.60      0.64      2376\n",
      "\n",
      "    accuracy                           0.58      7228\n",
      "   macro avg       0.72      0.58      0.54      7228\n",
      "weighted avg       0.72      0.58      0.54      7228\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2245    1  142]\n",
      " [1467  505  492]\n",
      " [ 956    2 1418]]\n",
      "✅ Model saved as: AdaBoost_Classifier.pkl\n",
      "\n",
      "🔍 Evaluation: Gradient Boosting Classifier\n",
      "Accuracy: 0.6854\n",
      "MCC: 0.5287\n",
      "Kappa Score: 0.5279\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.74      0.72      2388\n",
      "           0       0.61      0.63      0.62      2464\n",
      "           1       0.77      0.69      0.73      2376\n",
      "\n",
      "    accuracy                           0.69      7228\n",
      "   macro avg       0.69      0.69      0.69      7228\n",
      "weighted avg       0.69      0.69      0.69      7228\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1775  517   96]\n",
      " [ 522 1544  398]\n",
      " [ 274  467 1635]]\n",
      "✅ Model saved as: Gradient_Boosting_Classifier.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluation: Super Voting Classifier (All Ensembles Combined)\n",
      "Accuracy: 0.8493\n",
      "MCC: 0.7758\n",
      "Kappa Score: 0.7738\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.86      0.86      2388\n",
      "           0       0.82      0.92      0.87      2464\n",
      "           1       0.88      0.77      0.82      2376\n",
      "\n",
      "    accuracy                           0.85      7228\n",
      "   macro avg       0.85      0.85      0.85      7228\n",
      "weighted avg       0.85      0.85      0.85      7228\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2051  212  125]\n",
      " [  82 2262  120]\n",
      " [ 262  288 1826]]\n",
      "✅ Model saved as: Super_Voting_Classifier_All_Ensembles_Combined.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Evaluation: Custom Averaged Ensemble (Manual Soft Voting)\n",
      "Accuracy: 0.05118981737686774\n",
      "MCC: -0.2820566717592112\n",
      "Kappa Score: -0.24608810334550424\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      2388\n",
      "           0       0.03      0.03      0.03      2464\n",
      "           1       0.10      0.12      0.11      2376\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.05      7228\n",
      "   macro avg       0.03      0.04      0.04      7228\n",
      "weighted avg       0.05      0.05      0.05      7228\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   0 2051  212  125]\n",
      " [   0   82 2262  120]\n",
      " [   0  262  288 1826]\n",
      " [   0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    VotingClassifier,\n",
    "    BaggingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    cohen_kappa_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Best Individual Models\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    bootstrap=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_lr = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    penalty='l2',\n",
    "    max_iter=500,\n",
    "    C=10,\n",
    "    multi_class='auto',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_knn = KNeighborsClassifier(\n",
    "    n_neighbors=3,\n",
    "    weights='distance',\n",
    "    algorithm='kd_tree',\n",
    "    p=1,\n",
    "    leaf_size=20\n",
    ")\n",
    "\n",
    "# ✅ 1. Voting Classifier (Soft Voting)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', best_rf),\n",
    "        ('lr', best_lr),\n",
    "        ('knn', best_knn)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# ✅ 2. Bagging Classifier\n",
    "bagging_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=50,\n",
    "    max_samples=0.8,\n",
    "    max_features=0.8,\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ✅ 3. AdaBoost Classifier\n",
    "adaboost_clf = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ✅ 4. Gradient Boosting Classifier\n",
    "gboost_clf = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ✅ 5. Super Ensemble (Combines All Above Ensembles)\n",
    "super_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('vote', voting_clf),\n",
    "        ('bagging', bagging_clf),\n",
    "        ('adaboost', adaboost_clf),\n",
    "        ('gboost', gboost_clf)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "\n",
    "# ✅ Evaluation Function\n",
    "def evaluate_model(model, name, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\n🔍 Evaluation: {name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"MCC: {matthews_corrcoef(y_test, y_pred):.4f}\")\n",
    "    print(f\"Kappa Score: {cohen_kappa_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Save model\n",
    "    filename = name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"+\", \"plus\") + \".pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"✅ Model saved as: {filename}\")\n",
    "\n",
    "# ✅ Train and Evaluate All Models\n",
    "models = [\n",
    "    (voting_clf, \"Voting Classifier (RF + LR + KNN)\"),\n",
    "    (bagging_clf, \"Bagging Classifier (DT)\"),\n",
    "    (adaboost_clf, \"AdaBoost Classifier\"),\n",
    "    (gboost_clf, \"Gradient Boosting Classifier\"),\n",
    "    (super_ensemble, \"Super Voting Classifier (All Ensembles Combined)\")\n",
    "]\n",
    "\n",
    "# 🔁 Run all models (Assumes X_train, y_train, X_test, y_test are already defined)\n",
    "for model, name in models:\n",
    "    evaluate_model(model, name, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# ✅ Optional: Manual Averaging of Predicted Probabilities\n",
    "voting_clf.fit(X_train, y_train)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "gboost_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_proba = voting_clf.predict_proba(X_test)\n",
    "bagging_proba = bagging_clf.predict_proba(X_test)\n",
    "adaboost_proba = adaboost_clf.predict_proba(X_test)\n",
    "gboost_proba = gboost_clf.predict_proba(X_test)\n",
    "\n",
    "avg_proba = (voting_proba + bagging_proba + adaboost_proba + gboost_proba) / 4\n",
    "y_pred_avg = np.argmax(avg_proba, axis=1)\n",
    "\n",
    "print(\"\\n🧠 Evaluation: Custom Averaged Ensemble (Manual Soft Voting)\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_avg))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred_avg))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_avg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_avg))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dc2ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluation: Voting Classifier (RF + LR + KNN)\n",
      "Training Accuracy: 0.9645\n",
      "Testing Accuracy: 0.7575\n",
      "Cross-Validation Accuracy (5-fold): 0.7466\n",
      "MCC: 0.5889\n",
      "Kappa Score: 0.5818\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.82      0.77      1920\n",
      "           0       0.81      0.29      0.42       696\n",
      "           1       0.78      0.84      0.81      2394\n",
      "\n",
      "    accuracy                           0.76      5010\n",
      "   macro avg       0.77      0.65      0.67      5010\n",
      "weighted avg       0.76      0.76      0.74      5010\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1582   21  317]\n",
      " [ 240  199  257]\n",
      " [ 354   26 2014]]\n",
      "✅ Model saved as: Voting_Classifier_RF_plus_LR_plus_KNN.pkl\n",
      "\n",
      "🔍 Evaluation: Bagging Classifier (DT)\n",
      "Training Accuracy: 0.9624\n",
      "Testing Accuracy: 0.7808\n",
      "Cross-Validation Accuracy (5-fold): 0.7731\n",
      "MCC: 0.6295\n",
      "Kappa Score: 0.6246\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.84      0.81      1920\n",
      "           0       0.70      0.34      0.46       696\n",
      "           1       0.79      0.86      0.83      2394\n",
      "\n",
      "    accuracy                           0.78      5010\n",
      "   macro avg       0.76      0.68      0.70      5010\n",
      "weighted avg       0.77      0.78      0.77      5010\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1612   35  273]\n",
      " [ 192  235  269]\n",
      " [ 264   65 2065]]\n",
      "✅ Model saved as: Bagging_Classifier_DT.pkl\n",
      "\n",
      "🔍 Evaluation: AdaBoost Classifier\n",
      "Training Accuracy: 0.7228\n",
      "Testing Accuracy: 0.7208\n",
      "Cross-Validation Accuracy (5-fold): 0.7112\n",
      "MCC: 0.5213\n",
      "Kappa Score: 0.5100\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.75      0.73      1920\n",
      "           0       1.00      0.20      0.33       696\n",
      "           1       0.71      0.85      0.78      2394\n",
      "\n",
      "    accuracy                           0.72      5010\n",
      "   macro avg       0.81      0.60      0.61      5010\n",
      "weighted avg       0.75      0.72      0.70      5010\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1441    0  479]\n",
      " [ 225  139  332]\n",
      " [ 363    0 2031]]\n",
      "✅ Model saved as: AdaBoost_Classifier.pkl\n",
      "\n",
      "🔍 Evaluation: Gradient Boosting Classifier\n",
      "Training Accuracy: 0.7663\n",
      "Testing Accuracy: 0.7547\n",
      "Cross-Validation Accuracy (5-fold): 0.7518\n",
      "MCC: 0.5825\n",
      "Kappa Score: 0.5723\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.82      0.78      1920\n",
      "           0       0.91      0.21      0.34       696\n",
      "           1       0.76      0.86      0.81      2394\n",
      "\n",
      "    accuracy                           0.75      5010\n",
      "   macro avg       0.80      0.63      0.64      5010\n",
      "weighted avg       0.77      0.75      0.73      5010\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1576   11  333]\n",
      " [ 236  147  313]\n",
      " [ 333    3 2058]]\n",
      "✅ Model saved as: Gradient_Boosting_Classifier.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Evaluation: Custom Averaged Ensemble (Manual Soft Voting)\n",
      "Accuracy: 0.0509\n",
      "MCC: -0.0518\n",
      "Kappa Score: -0.0321\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1920\n",
      "           0       0.11      0.34      0.17       696\n",
      "           1       0.09      0.01      0.01      2394\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.05      5010\n",
      "   macro avg       0.05      0.09      0.05      5010\n",
      "weighted avg       0.06      0.05      0.03      5010\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   0 1630   16  274]\n",
      " [   0  236  182  278]\n",
      " [   0  287   19 2088]\n",
      " [   0    0    0    0]]\n",
      "\n",
      "📋 Tabulated Results:\n",
      "                               Model Train Acc  Test Acc CV Acc (5-fold)  \\\n",
      "0  Voting Classifier (RF + LR + KNN)    0.9645    0.7575          0.7466   \n",
      "1            Bagging Classifier (DT)    0.9624    0.7808          0.7731   \n",
      "2                AdaBoost Classifier    0.7228    0.7208          0.7112   \n",
      "3       Gradient Boosting Classifier    0.7663    0.7547          0.7518   \n",
      "4     Manual Soft Voting (Avg Proba)         -    0.0509               -   \n",
      "\n",
      "      MCC   Kappa  \n",
      "0  0.5889  0.5818  \n",
      "1  0.6295  0.6246  \n",
      "2  0.5213  0.5100  \n",
      "3  0.5825  0.5723  \n",
      "4 -0.0518 -0.0321  \n",
      "\n",
      "📁 Results saved to 'model_performance_summary.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, VotingClassifier, BaggingClassifier,\n",
    "    AdaBoostClassifier, GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, matthews_corrcoef, cohen_kappa_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 📌 Assume df_selected and df['rating'] are already defined\n",
    "X = df_selected\n",
    "y = df['rating']\n",
    "\n",
    "# 🧪 Train/Val/Test Split\n",
    "X_train_full, X_temp, y_train_full, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 🔄 Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_full = imputer.fit_transform(X_train_full)\n",
    "X_val = imputer.transform(X_val)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# 🎯 PCA: Fixed number of components (or you can use n_components=0.95 for 95% variance)\n",
    "pca = PCA(n_components=30)\n",
    "X_train_pca = pca.fit_transform(X_train_full)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# ✅ Base Models\n",
    "best_rf = RandomForestClassifier(n_estimators=100, max_depth=20, min_samples_split=2,\n",
    "                                 min_samples_leaf=1, bootstrap=False, random_state=42)\n",
    "best_lr = LogisticRegression(solver='lbfgs', penalty='l2', max_iter=500, C=10,\n",
    "                             multi_class='auto', random_state=42)\n",
    "best_knn = KNeighborsClassifier(n_neighbors=3, weights='distance',\n",
    "                                algorithm='kd_tree', p=1, leaf_size=20)\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# ✅ Ensemble Models\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', best_rf),\n",
    "    ('lr', best_lr),\n",
    "    ('knn', best_knn)\n",
    "], voting='soft')\n",
    "\n",
    "bagging_clf = BaggingClassifier(estimator=dt_clf, n_estimators=50,\n",
    "                                max_samples=0.8, max_features=0.8,\n",
    "                                bootstrap=True, random_state=42)\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
    "                                  n_estimators=50, learning_rate=1.0, random_state=42)\n",
    "\n",
    "gboost_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "                                        max_depth=3, random_state=42)\n",
    "\n",
    "# 🧠 Results table\n",
    "results = []\n",
    "\n",
    "# 📊 Evaluation Function with Tabulation\n",
    "def evaluate_model(model, name, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    cv_acc = np.mean(cv_scores)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n🔍 Evaluation: {name}\")\n",
    "    print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Testing Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Cross-Validation Accuracy (5-fold): {cv_acc:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "    print(f\"Kappa Score: {kappa:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Save model\n",
    "    filename = name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"+\", \"plus\") + \".pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"✅ Model saved as: {filename}\")\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train Acc': round(train_acc, 4),\n",
    "        'Test Acc': round(test_acc, 4),\n",
    "        'CV Acc (5-fold)': round(cv_acc, 4),\n",
    "        'MCC': round(mcc, 4),\n",
    "        'Kappa': round(kappa, 4)\n",
    "    })\n",
    "\n",
    "# 🚀 Train & Evaluate Supported Models\n",
    "models = [\n",
    "    (voting_clf, \"Voting Classifier (RF + LR + KNN)\"),\n",
    "    (bagging_clf, \"Bagging Classifier (DT)\"),\n",
    "    (adaboost_clf, \"AdaBoost Classifier\"),\n",
    "    (gboost_clf, \"Gradient Boosting Classifier\")\n",
    "]\n",
    "\n",
    "for model, name in models:\n",
    "    evaluate_model(model, name, X_train_pca, y_train_full, X_test_pca, y_test)\n",
    "\n",
    "# 🧪 Manual Soft Voting (Custom Averaged Probabilities)\n",
    "voting_clf.fit(X_train_pca, y_train_full)\n",
    "bagging_clf.fit(X_train_pca, y_train_full)\n",
    "adaboost_clf.fit(X_train_pca, y_train_full)\n",
    "gboost_clf.fit(X_train_pca, y_train_full)\n",
    "\n",
    "voting_proba = voting_clf.predict_proba(X_test_pca)\n",
    "bagging_proba = bagging_clf.predict_proba(X_test_pca)\n",
    "adaboost_proba = adaboost_clf.predict_proba(X_test_pca)\n",
    "gboost_proba = gboost_clf.predict_proba(X_test_pca)\n",
    "\n",
    "avg_proba = (voting_proba + bagging_proba + adaboost_proba + gboost_proba) / 4\n",
    "y_pred_avg = np.argmax(avg_proba, axis=1)\n",
    "\n",
    "manual_acc = accuracy_score(y_test, y_pred_avg)\n",
    "manual_mcc = matthews_corrcoef(y_test, y_pred_avg)\n",
    "manual_kappa = cohen_kappa_score(y_test, y_pred_avg)\n",
    "\n",
    "print(\"\\n🧠 Evaluation: Custom Averaged Ensemble (Manual Soft Voting)\")\n",
    "print(f\"Accuracy: {manual_acc:.4f}\")\n",
    "print(f\"MCC: {manual_mcc:.4f}\")\n",
    "print(f\"Kappa Score: {manual_kappa:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_avg))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_avg))\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Manual Soft Voting (Avg Proba)',\n",
    "    'Train Acc': '-',  # not computed\n",
    "    'Test Acc': round(manual_acc, 4),\n",
    "    'CV Acc (5-fold)': '-',\n",
    "    'MCC': round(manual_mcc, 4),\n",
    "    'Kappa': round(manual_kappa, 4)\n",
    "})\n",
    "\n",
    "# 📊 Final Results Table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n📋 Tabulated Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# 💾 Save to CSV\n",
    "results_df.to_csv(\"model_performance_summary.csv\", index=False)\n",
    "print(\"\\n📁 Results saved to 'model_performance_summary.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb4348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beaf3d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pca shape: (33728, 30), y_train shape: (33728,)\n",
      "X_val_pca shape: (5009, 30), y_val shape: (5009,)\n",
      "X_test_pca shape: (5010, 30), y_test shape: (5010,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA only on X_train\n",
    "pca = PCA(n_components=30)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# Transform validation and test using the same PCA\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Double-check shapes\n",
    "print(f\"X_train_pca shape: {X_train_pca.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val_pca shape: {X_val_pca.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test_pca shape: {X_test_pca.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719adec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "057530f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluation: Voting Classifier (RF + LR)\n",
      "✅ Training Accuracy: 0.9331\n",
      "✅ Testing Accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cross-Val Accuracy (5-fold): 0.8423 ± 0.0044\n",
      "✅ MCC: 0.8001\n",
      "✅ Kappa Score: 0.7978\n",
      "✅ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.91      0.89      1920\n",
      "           0       0.72      0.89      0.79       696\n",
      "           1       0.94      0.85      0.89      2394\n",
      "\n",
      "    accuracy                           0.88      5010\n",
      "   macro avg       0.84      0.88      0.86      5010\n",
      "weighted avg       0.88      0.88      0.88      5010\n",
      "\n",
      "✅ Confusion Matrix:\n",
      " [[1740   85   95]\n",
      " [  46  616   34]\n",
      " [ 210  156 2028]]\n",
      "💾 Model saved as: Voting_Classifier_RF_plus_LR.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluation: Voting Classifier (RF + LR + DT)\n",
      "✅ Training Accuracy: 0.9593\n",
      "✅ Testing Accuracy: 0.8681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cross-Val Accuracy (5-fold): 0.8096 ± 0.0035\n",
      "✅ MCC: 0.7909\n",
      "✅ Kappa Score: 0.7879\n",
      "✅ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.86      0.88      1920\n",
      "           0       0.66      0.92      0.77       696\n",
      "           1       0.93      0.86      0.89      2394\n",
      "\n",
      "    accuracy                           0.87      5010\n",
      "   macro avg       0.83      0.88      0.85      5010\n",
      "weighted avg       0.88      0.87      0.87      5010\n",
      "\n",
      "✅ Confusion Matrix:\n",
      " [[1655  141  124]\n",
      " [  23  638   35]\n",
      " [ 152  186 2056]]\n",
      "💾 Model saved as: Voting_Classifier_RF_plus_LR_plus_DT.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluation: Voting Classifier (RF + LR + KNN)\n",
      "✅ Training Accuracy: 0.9567\n",
      "✅ Testing Accuracy: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cross-Val Accuracy (5-fold): 0.8156 ± 0.0048\n",
      "✅ MCC: 0.8027\n",
      "✅ Kappa Score: 0.8003\n",
      "✅ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.89      0.89      1920\n",
      "           0       0.70      0.91      0.79       696\n",
      "           1       0.94      0.86      0.89      2394\n",
      "\n",
      "    accuracy                           0.88      5010\n",
      "   macro avg       0.84      0.89      0.86      5010\n",
      "weighted avg       0.89      0.88      0.88      5010\n",
      "\n",
      "✅ Confusion Matrix:\n",
      " [[1706  115   99]\n",
      " [  20  635   41]\n",
      " [ 186  159 2049]]\n",
      "💾 Model saved as: Voting_Classifier_RF_plus_LR_plus_KNN.pkl\n",
      "\n",
      "🔍 Evaluation: Bagging Classifier (DT)\n",
      "✅ Training Accuracy: 0.9598\n",
      "✅ Testing Accuracy: 0.8878\n",
      "✅ Cross-Val Accuracy (5-fold): 0.8438 ± 0.0034\n",
      "✅ MCC: 0.8210\n",
      "✅ Kappa Score: 0.8188\n",
      "✅ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.90      0.90      1920\n",
      "           0       0.71      0.92      0.81       696\n",
      "           1       0.94      0.87      0.90      2394\n",
      "\n",
      "    accuracy                           0.89      5010\n",
      "   macro avg       0.85      0.90      0.87      5010\n",
      "weighted avg       0.90      0.89      0.89      5010\n",
      "\n",
      "✅ Confusion Matrix:\n",
      " [[1734   88   98]\n",
      " [  25  642   29]\n",
      " [ 154  168 2072]]\n",
      "💾 Model saved as: Bagging_Classifier_DT.pkl\n",
      "\n",
      "🔍 Evaluation: AdaBoost Classifier\n",
      "✅ Training Accuracy: 0.5934\n",
      "✅ Testing Accuracy: 0.6497\n",
      "✅ Cross-Val Accuracy (5-fold): 0.6042 ± 0.0065\n",
      "✅ MCC: 0.4421\n",
      "✅ Kappa Score: 0.4392\n",
      "✅ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.70      0.68      1920\n",
      "           0       0.31      0.42      0.36       696\n",
      "           1       0.79      0.68      0.73      2394\n",
      "\n",
      "    accuracy                           0.65      5010\n",
      "   macro avg       0.59      0.60      0.59      5010\n",
      "weighted avg       0.68      0.65      0.66      5010\n",
      "\n",
      "✅ Confusion Matrix:\n",
      " [[1341  340  239]\n",
      " [ 216  293  187]\n",
      " [ 452  321 1621]]\n",
      "💾 Model saved as: AdaBoost_Classifier.pkl\n",
      "\n",
      "🔍 Evaluation: Gradient Boosting Classifier\n",
      "✅ Training Accuracy: 0.6989\n",
      "✅ Testing Accuracy: 0.7138\n",
      "✅ Cross-Val Accuracy (5-fold): 0.6806 ± 0.0012\n",
      "✅ MCC: 0.5607\n",
      "✅ Kappa Score: 0.5516\n",
      "✅ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.78      0.77      1920\n",
      "           0       0.35      0.59      0.44       696\n",
      "           1       0.89      0.70      0.78      2394\n",
      "\n",
      "    accuracy                           0.71      5010\n",
      "   macro avg       0.67      0.69      0.66      5010\n",
      "weighted avg       0.77      0.71      0.73      5010\n",
      "\n",
      "✅ Confusion Matrix:\n",
      " [[1501  334   85]\n",
      " [ 164  408  124]\n",
      " [ 299  428 1667]]\n",
      "💾 Model saved as: Gradient_Boosting_Classifier.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluation: Super Voting Classifier (All Ensembles Combined)\n",
      "✅ Training Accuracy: 0.9527\n",
      "✅ Testing Accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cross-Val Accuracy (5-fold): 0.8389 ± 0.0044\n",
      "✅ MCC: 0.8090\n",
      "✅ Kappa Score: 0.8065\n",
      "✅ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.90      0.90      1920\n",
      "           0       0.70      0.91      0.79       696\n",
      "           1       0.94      0.86      0.90      2394\n",
      "\n",
      "    accuracy                           0.88      5010\n",
      "   macro avg       0.84      0.89      0.86      5010\n",
      "weighted avg       0.89      0.88      0.88      5010\n",
      "\n",
      "✅ Confusion Matrix:\n",
      " [[1730  100   90]\n",
      " [  27  631   38]\n",
      " [ 171  175 2048]]\n",
      "💾 Model saved as: Super_Voting_Classifier_All_Ensembles_Combined.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Evaluation: Custom Averaged Ensemble (Manual Soft Voting)\n",
      "✅ Testing Accuracy: 0.0403\n",
      "✅ MCC: -0.1611\n",
      "✅ Kappa Score: -0.1157\n",
      "✅ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1920\n",
      "           0       0.01      0.04      0.02       696\n",
      "           1       0.19      0.07      0.11      2394\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.04      5010\n",
      "   macro avg       0.05      0.03      0.03      5010\n",
      "weighted avg       0.09      0.04      0.05      5010\n",
      "\n",
      "✅ Confusion Matrix:\n",
      " [[   0 1730  100   90]\n",
      " [   0   27  631   38]\n",
      " [   0  171  175 2048]\n",
      " [   0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\prath\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, VotingClassifier, \n",
    "    BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, matthews_corrcoef, cohen_kappa_score, \n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Define Base Models with Best Params\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=20, min_samples_split=2,\n",
    "    min_samples_leaf=1, bootstrap=False, random_state=42\n",
    ")\n",
    "\n",
    "best_lr = LogisticRegression(\n",
    "    solver='lbfgs', penalty='l2', max_iter=500, C=10,\n",
    "    multi_class='auto', random_state=42\n",
    ")\n",
    "\n",
    "best_knn = KNeighborsClassifier(\n",
    "    n_neighbors=3, weights='distance', algorithm='kd_tree',\n",
    "    p=1, leaf_size=20\n",
    ")\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# ✅ 1. Voting Classifier (RF + LR)\n",
    "voting_rf_lr = VotingClassifier(\n",
    "    estimators=[('rf', best_rf), ('lr', best_lr)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# ✅ 2. Voting Classifier (RF + LR + DT)\n",
    "voting_rf_lr_dt = VotingClassifier(\n",
    "    estimators=[('rf', best_rf), ('lr', best_lr), ('dt', dt_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# ✅ 3. Voting Classifier (RF + LR + KNN)\n",
    "voting_rf_lr_knn = VotingClassifier(\n",
    "    estimators=[('rf', best_rf), ('lr', best_lr), ('knn', best_knn)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# ✅ 4. Bagging Classifier\n",
    "bagging_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), n_estimators=50,\n",
    "    max_samples=0.8, max_features=0.8, bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ✅ 5. AdaBoost Classifier\n",
    "adaboost_clf = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50,\n",
    "    learning_rate=1.0, random_state=42\n",
    ")\n",
    "\n",
    "# ✅ 6. Gradient Boosting Classifier\n",
    "gboost_clf = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42\n",
    ")\n",
    "\n",
    "# ✅ 7. Super Ensemble (All Ensembles Combined)\n",
    "super_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('v1', voting_rf_lr_knn),\n",
    "        ('b1', bagging_clf),\n",
    "        ('a1', adaboost_clf),\n",
    "        ('g1', gboost_clf)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# ✅ Evaluation Function\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_model(model, name, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    print(f\"\\n🔍 Evaluation: {name}\")\n",
    "    print(f\"✅ Training Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "    print(f\"✅ Testing Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    \n",
    "    # Cross-validation (5-fold)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(f\"✅ Cross-Val Accuracy (5-fold): {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
    "\n",
    "    print(f\"✅ MCC: {matthews_corrcoef(y_test, y_pred):.4f}\")\n",
    "    print(f\"✅ Kappa Score: {cohen_kappa_score(y_test, y_pred):.4f}\")\n",
    "    print(\"✅ Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"✅ Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Save model\n",
    "    filename = name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"+\", \"plus\") + \".pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"💾 Model saved as: {filename}\")\n",
    "\n",
    "# ✅ All Models with Names\n",
    "models = [\n",
    "    (voting_rf_lr, \"Voting Classifier (RF + LR)\"),\n",
    "    (voting_rf_lr_dt, \"Voting Classifier (RF + LR + DT)\"),\n",
    "    (voting_rf_lr_knn, \"Voting Classifier (RF + LR + KNN)\"),\n",
    "    (bagging_clf, \"Bagging Classifier (DT)\"),\n",
    "    (adaboost_clf, \"AdaBoost Classifier\"),\n",
    "    (gboost_clf, \"Gradient Boosting Classifier\"),\n",
    "    (super_ensemble, \"Super Voting Classifier (All Ensembles Combined)\")\n",
    "]\n",
    "\n",
    "# ✅ PCA-reduced data assumed as input\n",
    "# Replace these with your actual PCA reduced data variables\n",
    "# X_train_pca, X_test_pca, y_train, y_test\n",
    "\n",
    "# Run all models on PCA data\n",
    "for model, name in models:\n",
    "    evaluate_model(model, name, X_train_pca, y_train, X_test_pca, y_test)\n",
    "\n",
    "# ✅ 8. Manual Averaged Ensemble\n",
    "# Train base ensemble models\n",
    "voting_rf_lr_knn.fit(X_train_pca, y_train)\n",
    "bagging_clf.fit(X_train_pca, y_train)\n",
    "adaboost_clf.fit(X_train_pca, y_train)\n",
    "gboost_clf.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "proba_vote = voting_rf_lr_knn.predict_proba(X_test_pca)\n",
    "proba_bag = bagging_clf.predict_proba(X_test_pca)\n",
    "proba_ada = adaboost_clf.predict_proba(X_test_pca)\n",
    "proba_gboost = gboost_clf.predict_proba(X_test_pca)\n",
    "\n",
    "# Average probabilities and predict\n",
    "avg_proba = (proba_vote + proba_bag + proba_ada + proba_gboost) / 4\n",
    "y_pred_avg = np.argmax(avg_proba, axis=1)\n",
    "\n",
    "print(\"\\n🧠 Evaluation: Custom Averaged Ensemble (Manual Soft Voting)\")\n",
    "print(f\"✅ Testing Accuracy: {accuracy_score(y_test, y_pred_avg):.4f}\")\n",
    "print(f\"✅ MCC: {matthews_corrcoef(y_test, y_pred_avg):.4f}\")\n",
    "print(f\"✅ Kappa Score: {cohen_kappa_score(y_test, y_pred_avg):.4f}\")\n",
    "print(\"✅ Classification Report:\\n\", classification_report(y_test, y_pred_avg))\n",
    "print(\"✅ Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed4a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ac7ce8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   reviewer_id  store_name              category  \\\n",
      "0            1  McDonald's  Fast food restaurant   \n",
      "1            2  McDonald's  Fast food restaurant   \n",
      "2            3  McDonald's  Fast food restaurant   \n",
      "3            4  McDonald's  Fast food restaurant   \n",
      "4            5  McDonald's  Fast food restaurant   \n",
      "\n",
      "                                       store_address  latitude   longitude  \\\n",
      "0  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
      "1  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
      "2  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
      "3  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
      "4  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
      "\n",
      "  rating_count   review_time  \\\n",
      "0        1,240  3 months ago   \n",
      "1        1,240    5 days ago   \n",
      "2        1,240    5 days ago   \n",
      "3        1,240   a month ago   \n",
      "4        1,240  2 months ago   \n",
      "\n",
      "                                              review   rating  \n",
      "0  Why does it look like someone spit on my food?...   1 star  \n",
      "1  It'd McDonalds. It is what it is as far as the...  4 stars  \n",
      "2  Made a mobile order got to the speaker and che...   1 star  \n",
      "3  My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...  5 stars  \n",
      "4  I repeat my order 3 times in the drive thru, a...   1 star  \n",
      "\n",
      "Shape:  (33396, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "#Load the dataset\n",
    "#df = pd.read_csv(\"drive/MyDrive/McDonald_s_Reviews.csv\", encoding=\"latin1\")\n",
    "df = pd.read_csv(\"McDonald_s_Reviews.csv\", encoding=\"latin1\")\n",
    "print(df.head())\n",
    "print(\"\\nShape: \", df.shape)\n",
    "\n",
    "# Ensure it's a list of strings, not list of lists\n",
    "X_train = df['review'].tolist()\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Save the vectorizer for use in your app\n",
    "import pickle\n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490963b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
